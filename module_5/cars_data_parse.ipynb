{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "extraordinary-behavior",
   "metadata": {},
   "source": [
    "# Сбор данный для обучения модели с сайта auto.ru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "historic-truck",
   "metadata": {},
   "outputs": [],
   "source": [
    "#импортирование необходимый библиотек\n",
    "import pandas as pd\n",
    "import time\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import unicodedata\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "hearing-georgia",
   "metadata": {},
   "outputs": [],
   "source": [
    "#марки атвомобилей, по которым будет производится сбор данных\n",
    "brands = {'audi',\n",
    " 'bmw',\n",
    " 'honda',\n",
    " 'infiniti',\n",
    " 'lexus',\n",
    " 'mercedes',\n",
    " 'mitsubishi',\n",
    " 'nissan',\n",
    " 'skoda',\n",
    " 'toyota',\n",
    " 'volkswagen',\n",
    " 'volvo'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "frequent-hunter",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_car_links(car, year_from = '1900', year_to='2020'):\n",
    "    \"\"\"Функция парсит страницу марки и вытаскивает ссылки на объявления.\n",
    "        На вход получает марку автомобиля и опционально период производства (по умолчанию 1900-2020)\n",
    "        На выходе список ссылок на все автомобили данной марки с годом производства\n",
    "        в указанном периоде, размещенные на auto.ru\"\"\"\n",
    "    links =[]\n",
    "    request = requests.get('https://auto.ru/rossiya/cars/'+car+'/all/?year_from='+year_from+'&year_to='+year_to)\n",
    "    if request.status_code != 200:\n",
    "        return \"Connection problem\"\n",
    "    request.encoding = 'utf-8'\n",
    "    car_page = request.text\n",
    "    car_parse = BeautifulSoup(car_page, 'html.parser')\n",
    "    car_count = car_parse.find(\"span\", class_=\"ButtonWithLoader__content\",)\n",
    "    #колличество объеявлений данной марки\n",
    "    count = int(''.join(unicodedata.normalize(\"NFKD\",car_count.text)[9:-12].split()))\n",
    "    print('{0} - {1}'.format(car, count))\n",
    "    p = 1\n",
    "    while len(links) < count:\n",
    "        request = requests.get('https://auto.ru/rossiya/cars/'+car+'/all/?page='+str(p)+'&year_from=2007&year_to=2008')\n",
    "        if request.status_code != 200:\n",
    "            break\n",
    "        request.encoding = 'utf-8'\n",
    "        car_page = request.text\n",
    "        urls_parse = BeautifulSoup(car_page, 'html.parser')\n",
    "        time.sleep(2)\n",
    "        p += 1 #переходим на след. страницу\n",
    "        cars_urls = urls_parse.find_all(\"a\", class_=\"Link ListingItemTitle-module__link\")\n",
    "        #Отбираем ссылки ведущие к конкретному предложению и собираем в список\n",
    "        for item in cars_urls:\n",
    "            url = item.get('href')\n",
    "            links.append(url)\n",
    "    return links #возвращаем ссылки на предложения по модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "sensitive-default",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_car_info(url):\n",
    "    \"\"\"Функция собирает информацию по ссылке объявления.\n",
    "        На вход принимает ссылку на объявление\n",
    "        На выходе список искомых данных\"\"\"\n",
    "    data =[]\n",
    "    request = requests.get(url)\n",
    "    if request.status_code != 200:\n",
    "        return None    \n",
    "    request.encoding = 'utf-8'\n",
    "    car_page = request.text\n",
    "    car_parse = BeautifulSoup(car_page, 'html.parser')\n",
    "    #тип кузова\n",
    "    bodytype_parse = car_parse.find(\"li\", class_='CardInfoRow CardInfoRow_bodytype')\n",
    "    if bodytype_parse:\n",
    "        bodytype = bodytype_parse.a.text\n",
    "        data.append(bodytype)\n",
    "    else:\n",
    "        data.append(None)\n",
    "    #Brand\n",
    "    brand = url.split('/')[6].upper()\n",
    "    data.append(brand)    \n",
    "    #url\n",
    "    data.append(url)\n",
    "    #цвет\n",
    "    color_parse = car_parse.find(\"li\", class_='CardInfoRow CardInfoRow_color')\n",
    "    if color_parse:\n",
    "        color = color_parse.a.text\n",
    "        data.append(color)\n",
    "    else:\n",
    "        data.append(None)\n",
    "    #опции\n",
    "    options = {}\n",
    "    addition_items = car_parse.find_all('div', class_='ComplectationGroups__group')\n",
    "    for option in addition_items:\n",
    "        name = option.find_all('div')[0]['data-group']\n",
    "        option_parse = option.ul.find_all('li')\n",
    "        new = []\n",
    "        for item in option_parse:\n",
    "            new.append(item.text)\n",
    "        options[name] = new\n",
    "    data.append(options)\n",
    "    #текст\n",
    "    text_parse = car_parse.find(\"div\", class_='CardDescription__textInner')\n",
    "    if text_parse:\n",
    "        text = text_parse.span.text\n",
    "        data.append(text)\n",
    "    else:\n",
    "        data.append(None)\n",
    "    #двигатель\n",
    "    engine_parse = car_parse.find(\"li\", class_='CardInfoRow CardInfoRow_engine')\n",
    "    if engine_parse:\n",
    "        engine_parse_clear = unicodedata.normalize(\"NFKD\", engine_parse.find_all('span')[1].text).split('/')\n",
    "        #объем двигателя\n",
    "        engine_displacement = float(engine_parse_clear[0].split()[0])\n",
    "        data.append(engine_displacement)\n",
    "        #мощьность\n",
    "        enginepower = int(engine_parse_clear[1].split()[0])\n",
    "        data.append(enginepower) \n",
    "        #топливо\n",
    "        fuelType = engine_parse_clear[2].strip()\n",
    "        data.append(fuelType)\n",
    "    else:\n",
    "        data.append(None)\n",
    "        data.append(None)\n",
    "        data.append(None)        \n",
    "    #пробег\n",
    "    mileage_parse = car_parse.find(\"li\", class_='CardInfoRow CardInfoRow_kmAge')\n",
    "    if mileage_parse:\n",
    "        mileage = int(''.join(unicodedata.normalize(\"NFKD\", mileage_parse.find_all('span')[1].text)[:-3].split()))\n",
    "        data.append(mileage) \n",
    "    else:\n",
    "        data.append(None)\n",
    "    #model\n",
    "    model = url.split('/')[7]\n",
    "    data.append(model)\n",
    "    #name\n",
    "    name_parse = car_parse.find_all(\"a\", class_='Link Link_color_gray CardBreadcrumbs__itemText')\n",
    "    if name_parse:\n",
    "        name = unicodedata.normalize(\"NFKD\", name_parse[4].text)\n",
    "        data.append(name)\n",
    "    else:\n",
    "        data.append(None)\n",
    "    #год\n",
    "    year_parse = car_parse.find(\"li\", class_='CardInfoRow CardInfoRow_year')\n",
    "    if year_parse:\n",
    "        year = year_parse.a.text\n",
    "        data.append(year)\n",
    "    else:\n",
    "        data.append(None)\n",
    "    #трансмиссия\n",
    "    transmission_parse = car_parse.find(\"li\", class_='CardInfoRow CardInfoRow_transmission')\n",
    "    if transmission_parse:\n",
    "        transmission = transmission_parse.find_all('span')[1].text\n",
    "        data.append(transmission)\n",
    "    else:\n",
    "        data.append(None)\n",
    "    #владельцы\n",
    "    owners_parse = car_parse.find('li', class_='CardInfoRow CardInfoRow_ownersCount')\n",
    "    if owners_parse:\n",
    "        owners = owners_parse.find_all('span')[1].text\n",
    "        data.append(owners)\n",
    "    else:\n",
    "        data.append(None)\n",
    "    #птс\n",
    "    pts_parse = car_parse.find('li', class_='CardInfoRow CardInfoRow_pts')\n",
    "    if pts_parse:\n",
    "        pts = pts_parse.find_all('span')[1].text\n",
    "        data.append(pts)\n",
    "    else:\n",
    "        data.append(None)\n",
    "    #владение\n",
    "    owningtime_parse = car_parse.find('li', class_='CardInfoRow CardInfoRow_owningTime')\n",
    "    if owningtime_parse:\n",
    "        owningtime = owningtime_parse.find_all('span')[1].text\n",
    "        data.append(owningtime)\n",
    "    else:\n",
    "        data.append(None)\n",
    "    #привод\n",
    "    drive_parse = car_parse.find('li', class_='CardInfoRow CardInfoRow_drive')\n",
    "    if drive_parse:\n",
    "        drive = drive_parse.find_all('span')[1].text\n",
    "        data.append(drive)\n",
    "    else:\n",
    "        data.append(None)\n",
    "    #руль\n",
    "    wheel_parse = car_parse.find('li', class_='CardInfoRow CardInfoRow_wheel')\n",
    "    if wheel_parse:\n",
    "        wheel = wheel_parse.find_all('span')[1].text\n",
    "        data.append(wheel)\n",
    "    else:\n",
    "        data.append(None)\n",
    "    #цена    \n",
    "    price_parse = car_parse.find(\"div\", class_='InfoPopup InfoPopup_theme_plain InfoPopup_withChildren PriceUsedOffer-module__price')\n",
    "    if price_parse: \n",
    "        price = int(''.join(unicodedata.normalize(\"NFKD\", price_parse.find_all('span')[1].text)[:-2].split()))\n",
    "        data.append(price)\n",
    "    else:\n",
    "        return None\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "through-enzyme",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bmw - 442\n"
     ]
    }
   ],
   "source": [
    "#собираем все ссылки на искомые марки в списке brends в единый список car_links\n",
    "car_links = []\n",
    "for brand in brands:\n",
    "    car_links.extend(get_car_links(brand, year_from='1914', year_to='2000'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "assisted-hollow",
   "metadata": {},
   "outputs": [],
   "source": [
    "#созраняем данные для дальнейшего использования\n",
    "with open('data/car_links.json', 'w') as f:\n",
    "    f.write(json.dumps(car_links))\n",
    "#загружаем данные\n",
    "with open('data/car_links.json', 'r') as f:\n",
    "    car_links = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "forbidden-sapphire",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data0 -  1.0%\n",
      "data1 -  1.0%\n",
      "data2 -  1.0%\n",
      "data3 -  1.0%\n",
      "Parsing complit 5 files created\n"
     ]
    }
   ],
   "source": [
    "#собираем данные из сылок в списке car_links, каждые 10000 записей сохраняем в DF и записываем в файл\n",
    "data = [] \n",
    "files = []\n",
    "file = 0\n",
    "for item in car_links:\n",
    "    taken_data = get_car_info(item) \n",
    "    time.sleep(2)\n",
    "    if taken_data:\n",
    "        data.append(taken_data)\n",
    "        length = len(data)\n",
    "    if length%10000 == 0:\n",
    "        print('data/data{} -  {}%'.format(file, (length/10000)*100)) #периодический вывод информации о протекающем процессе\n",
    "    if length >= 10000:\n",
    "        df = pd.DataFrame(data)\n",
    "        df.to_csv('data/data{}.csv'.format(file), index=False, encoding='utf8') #записываем данные в файл\n",
    "        files.append('data/data{}.csv'.format(file)) #сохраняем список созданных файлов\n",
    "        file += 1\n",
    "        data = [] #обнуляем список\n",
    "df = pd.DataFrame(data)\n",
    "files.append('data/data{}.csv'.format(file))\n",
    "df.to_csv('data/data{}.csv'.format(file), index=False, encoding='utf8') #записываем данные в файл\n",
    "with open('data/data_files.txt', 'w') as f:\n",
    "    f.write(json.dumps(files))\n",
    "print('Parsing complit {} files created'.format(file+1))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "distant-association",
   "metadata": {},
   "outputs": [],
   "source": [
    "#собираем данные в единый датафрейм\n",
    "with open('data/data_files.txt', 'r') as f:\n",
    "    files = json.load(f)\n",
    "data_files = [pd.read_csv(fname) for fname in files]\n",
    "data = pd.concat(data_files)\n",
    "#сохраняем данные в файл\n",
    "data.columns = ['bodyType', 'brand', 'car_url', 'color', 'options', 'description', 'engineDisplacement',\n",
    "                'enginePower', 'fuelType', 'mileage','model_name', 'name', 'productionDate', 'vehicleTransmission',\n",
    "                'owners', 'pts', 'own', 'drive', 'wheel', 'price']\n",
    "data.to_csv('data/data.csv', index=False, encoding='utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "minus-token",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
